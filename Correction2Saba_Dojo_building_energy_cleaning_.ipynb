{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mars241/CheckPoints/blob/main/Correction2Saba_Dojo_building_energy_cleaning_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![banniere.jpg](attachment:4dbde187-75c8-40df-8c7e-81bad382a3ec.jpg)"
      ],
      "metadata": {
        "id": "-sJ6llv5pJtw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"#1d479b\">Contexte</font>\n",
        "\n",
        "Pour atteindre l'objectif de **ville neutre en émissions de carbone en 2050**, la ville de **Seattle** s’intéresse de près aux émissions des bâtiments non destinés à l’habitation.\n",
        "\n",
        "Des relevés minutieux ont été effectués en 2015 et en 2016. Cependant, ces relevés sont coûteux à obtenir, et à partir de ceux déjà réalisés, nous devons tenter de prédire les émissions de CO2 et la consommation totale d’énergie de bâtiments pour lesquels elles n’ont pas encore été mesurées.\n",
        "\n",
        "<hr width=\"50%\" align=\"center\"/>\n",
        "\n",
        "Dans cette première partie, nous allons réaliser une **courte analyse exploratoire** après avoir nettoyé les données si besoin. Le but sera de déterminer les variables pertinentes ou d'en créer de nouvelles *(feature engineering)*."
      ],
      "metadata": {
        "id": "l25lHjQMpJtx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"#1d479b\">Sommaire</font>\n",
        "\n",
        "1. [Chargement et adaptation des données de relèves](#section_1)     \n",
        "    1.1. [Comparaison des colonnes des datasets](#section_1_1)     \n",
        "    1.2. [Décompactage des données de localisation de 2015](#section_1_2)     \n",
        "    1.3. [Description et nettoyage des données](#section_1_3)     \n",
        "2. [Analyse exploratoire & Feature Engineering](#section_2)      \n",
        "    2.1. [Les types de bâtiments](#section_2_1)     \n",
        "    2.2. [Les années de construction](#section_2_2)     \n",
        "    2.3. [Les corrélations linéaires](#section_2_3)     \n",
        "    2.4. [Analyse des variables à prédire](#section_2_4)\n",
        "3. [Dernières étapes de nettoyage](#section_3)\n",
        "4. [Projection des établissements sur la carte de Seattle](#section_4)"
      ],
      "metadata": {
        "id": "J2jGxW7ppJty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#337da4\" id=\"section_1\">1. Chargement et adaptation des données de relèves</font>"
      ],
      "metadata": {
        "id": "XeH7ulgOpJtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "import seaborn as sns\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.color_palette(\"crest\", as_cmap=True)\n",
        "\n",
        "#Lecture du dossier data Kaggle\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "khQvRkmopJtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2015 = pd.read_csv(\"../input/sea-building-energy-benchmarking/2015-building-energy-benchmarking.csv\")\n",
        "data_2015.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "_IzzTScVpJt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2016 = pd.read_csv(\"../input/sea-building-energy-benchmarking/2016-building-energy-benchmarking.csv\")\n",
        "data_2016.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "E6vgPWYDpJt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Après avoir visualisé les premières lignes de ces 2 datasets, on remarque déjà que les colonnes ne sont pas identiques. Identifions les différences :"
      ],
      "metadata": {
        "id": "4KXelFuUpJt1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=\"#2cb7b0\" id=\"section_1_1\">1.1. Comparaison des colonnes des datasets</font>"
      ],
      "metadata": {
        "id": "VA4EdizLpJt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_colums(df1,df2):\n",
        "    columns_1 = list(df1.columns)\n",
        "    columns_2 = list(df2.columns)\n",
        "    same_columns=[]\n",
        "    diff_columns_2=[]\n",
        "    diff_columns_1=[]\n",
        "\n",
        "    for col in columns_2:\n",
        "        if col in columns_1:\n",
        "            same_columns.append(col)\n",
        "        else:\n",
        "            diff_columns_2.append(col)\n",
        "    for col in columns_1:\n",
        "        if col not in columns_2:\n",
        "            diff_columns_1.append(col)\n",
        "    return diff_columns_1, diff_columns_2"
      ],
      "metadata": {
        "trusted": true,
        "id": "EAn-GqG6pJt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diff_columns_2015, diff_columns_2016 = compare_colums(data_2015,data_2016)\n",
        "diff_columns_2015"
      ],
      "metadata": {
        "trusted": true,
        "id": "aVAb9AdOpJt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diff_columns_2016"
      ],
      "metadata": {
        "trusted": true,
        "id": "XMJKUGG1pJt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les **données de localisation** ont évolué entre 2015 et 2016. On retrouve en plus l'adresse, la ville et la localisation GPS a été segmentée en `Latitude` et `Longitude`. Certaines autres variables comme `GHGEmissions(MetricTonsCO2e)` ont changé de nom *(il faudra vérifier si l'odre de grandeur des données à changer comparativement à* `TotalGHGEmissions` *de 2016)*."
      ],
      "metadata": {
        "id": "pODLSEWlpJt3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=\"#2cb7b0\" id=\"section_1_2\">1.2. Décompactage des données de localisation de 2015</font>"
      ],
      "metadata": {
        "id": "OL0d30sZpJt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_2015['Location'][0]"
      ],
      "metadata": {
        "trusted": true,
        "id": "Od-jWAvqpJt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On remarque que les données de localisation pour le jeu de données de 2015 sont \"compactées\" dans une sorte de double dictionnaire. Nous allons donc travailler cette variable pour extraire chacune des variables imbriquées :"
      ],
      "metadata": {
        "id": "m4VQZf9zpJt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "data_2015['Location'] = [ast.literal_eval(str(item)) for index, item in data_2015.Location.iteritems()]\n",
        "data_2015 = pd.concat([data_2015.drop(['Location'], axis=1), data_2015['Location'].apply(pd.Series)], axis=1)\n",
        "data_2015['human_address'] = [ast.literal_eval(str(item)) for index, item in data_2015.human_address.iteritems()]\n",
        "data_2015 = pd.concat([data_2015.drop(['human_address'], axis=1), data_2015['human_address'].apply(pd.Series)], axis=1)\n",
        "data_2015.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "cUSRqhXapJt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous avons à présent les colonnes correspondant à celles de 2016 : `latitude`, `longitude`, `address`, `city`, `state` et `zip`. Renommons les de la même façon :"
      ],
      "metadata": {
        "id": "F0suqbShpJt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_2015 = data_2015.rename(columns={\"latitude\":\"Latitude\", \"longitude\":\"Longitude\",\n",
        "                                      \"address\":\"Address\", \"city\":\"City\",\n",
        "                                      \"state\":\"State\", \"zip\":\"ZipCode\"})"
      ],
      "metadata": {
        "trusted": true,
        "id": "otS4XMEgpJt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Puis regardons à nouveau les différences de colonnes entre les 2 dataframes :"
      ],
      "metadata": {
        "id": "BNyz0O1ipJt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diff_columns_2015, diff_columns_2016 = compare_colums(data_2015,data_2016)\n",
        "diff_columns_2015"
      ],
      "metadata": {
        "trusted": true,
        "id": "cGn6Sk1TpJt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diff_columns_2016"
      ],
      "metadata": {
        "trusted": true,
        "id": "vVqqnlCypJt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Description de la variable TotalGHGEmissions 2016 : \\n\\n\",data_2016['TotalGHGEmissions'].describe(),\n",
        "     f\"\\n\\nDescription de la variable GHGEmissions(MetricTonsCO2e) 2015 : \\n\\n\", data_2015['GHGEmissions(MetricTonsCO2e)'].describe())"
      ],
      "metadata": {
        "trusted": true,
        "id": "X93vOWoRpJt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les odres de grandeur des 2 variables sont identiques entre 2015 et 2016. Nous allons donc simplement renomer les colonnes à l'identique. Nous supprimons également les colonnes de 2015 n'ayant pas d'équivalent en 2016:"
      ],
      "metadata": {
        "id": "qVWKafkdpJt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_2015 = data_2015.rename(columns={'GHGEmissions(MetricTonsCO2e)':'TotalGHGEmissions',\n",
        "                                     'GHGEmissionsIntensity(kgCO2e/ft2)':'GHGEmissionsIntensity',\n",
        "                                     'Comment':'Comments'})\n",
        "data_2015.drop(['OtherFuelUse(kBtu)','2010 Census Tracts',\n",
        "                'Seattle Police Department Micro Community Policing Plan Areas',\n",
        "                'City Council Districts','SPD Beats', 'Zip Codes'], axis=1, inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "__tRkKLLpJt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diff_columns_2015, diff_columns_2016 = compare_colums(data_2015,data_2016)\n",
        "print(diff_columns_2015,diff_columns_2016)"
      ],
      "metadata": {
        "trusted": true,
        "id": "aYAAX0U6pJt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Les variables des 2 datasets étant à présent identiques**, nous allons pouvoir les regrouper en un unique jeu de données :"
      ],
      "metadata": {
        "id": "jma2b8NnpJt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.concat([data_2015[data_2016.columns],data_2016], axis = 0).sort_values([\"DataYear\", \"OSEBuildingID\"])\n",
        "data.shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "QsKpyNqlpJt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=\"#2cb7b0\" id=\"section_1_3\">1.3. Description et nettoyage des données</font>"
      ],
      "metadata": {
        "id": "6VKJK9mNpJt7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il est précisié dans le projet que **seuls les bâtiments non destinés à l'habitation seront étudiés**. Nous allons donc supprimer toutes les lignes correspondant à des habitations en nous basant sur la variable `BuildingType`"
      ],
      "metadata": {
        "id": "Gg_Fy6dopJt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['BuildingType'].unique()"
      ],
      "metadata": {
        "trusted": true,
        "id": "gu7NGlkvpJt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[~data['BuildingType'].str.contains(\"Multifamily\")]\n",
        "data['BuildingType'].unique()"
      ],
      "metadata": {
        "trusted": true,
        "id": "i0IEURM2pJt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Le jeu de données compte à présent {} lignes et {} colonnes.\".format(data.shape[0],data.shape[1]))"
      ],
      "metadata": {
        "trusted": true,
        "id": "tQPL83U7pJt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons également regarder s'il existe des **doublons sur l'identifiant** `OSEBuildingID`. On effet, nos modélisations devront porter sur un bâtiement unique *(ce n'est pas une modélisation temporelle)*. Nous prendrons donc en valeur la moyenne des variables sur les 2 années :"
      ],
      "metadata": {
        "id": "4vm411t5pJt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_columns = ['NumberofBuildings', 'NumberofFloors', 'PropertyGFATotal',\n",
        "                'PropertyGFAParking', 'PropertyGFABuilding(s)',\n",
        "                'LargestPropertyUseTypeGFA', 'SecondLargestPropertyUseTypeGFA',\n",
        "                'ThirdLargestPropertyUseTypeGFA', 'ENERGYSTARScore', 'SiteEUI(kBtu/sf)',\n",
        "                'SiteEUIWN(kBtu/sf)', 'SourceEUI(kBtu/sf)', 'SourceEUIWN(kBtu/sf)',\n",
        "                'SiteEnergyUse(kBtu)', 'SiteEnergyUseWN(kBtu)', 'SteamUse(kBtu)',\n",
        "                'Electricity(kWh)', 'Electricity(kBtu)', 'NaturalGas(therms)',\n",
        "                'NaturalGas(kBtu)', 'TotalGHGEmissions', 'GHGEmissionsIntensity']\n",
        "OSEBuilding_means = data[['OSEBuildingID']+mean_columns].groupby('OSEBuildingID').mean()\n",
        "OSEBuilding_means.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "CoEz6UIypJt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicate_building = data.drop_duplicates(subset=['OSEBuildingID'], keep='last')\n",
        "duplicate_building.drop(mean_columns, axis=1, inplace=True)\n",
        "data = pd.merge(duplicate_building, OSEBuilding_means, how='left', on='OSEBuildingID')"
      ],
      "metadata": {
        "trusted": true,
        "id": "IsgJpplopJt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le jeu de données ne compte à présent plus de doublons sur la variable `OSEBuildingID`.\n",
        "\n",
        "Regardons à présent les infos et descriptions du dataset :"
      ],
      "metadata": {
        "id": "8ugcYagMpJt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "trusted": true,
        "id": "62J-YzA1pJt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans la visualisation ci-dessus, certaines variables apparaissent déjà comme redondantes :\n",
        "- `Electricity(kWh)` et `Electricity(kBtu)`,\n",
        "- `NaturalGas(therms)` et `NaturalGas(kBtu)`\n",
        "- Les suffixes **WN** : \"Weather Normalized\" - Ce sont les mesures normalisées avec les conditions climatiques. Dans le cadre de notre analyse, la météo ne rentrera pas en compte.\n",
        "\n",
        "Nous allons donc commencer par supprimer ces variables :"
      ],
      "metadata": {
        "id": "HOf-sB_2pJt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_componant(df, suffix=None):\n",
        "  componant = []\n",
        "  for col in df.columns:\n",
        "      if suffix in col:\n",
        "        componant.append(col)\n",
        "  return componant"
      ],
      "metadata": {
        "trusted": true,
        "id": "cl1NpkSwpJt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Suppression des variables WN\n",
        "data.drop(search_componant(data,'WN'), axis=1, inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "TmVImw5qpJt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Suppression des variables redondantes\n",
        "redundant_features = ['NaturalGas(therms)','Electricity(kWh)']\n",
        "data.drop(redundant_features, axis=1, inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "mPqFZsxspJt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On remarque également des variables suffixées **GFA** : Elles représente la surface au sol *(Ground Floor Area)*. Nous les conservons donc pour la suite des analyses."
      ],
      "metadata": {
        "id": "a5HVdMx9pJt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "trusted": true,
        "id": "IXAIIz15pJt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans le cadre de nos modélisations, les variables à prédire sont la **consommation d'énergie du bâtiment** (`SiteEnergyUse(kBtu)`) et ses **émissions de CO2** (`TotalGHGEmissions`). Certaines lignes comportent des manquants sur ces variables, nous allons donc les supprimer :"
      ],
      "metadata": {
        "id": "yIBWuF4ApJt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[~((data['SiteEnergyUse(kBtu)'].isnull()) | (data['TotalGHGEmissions'].isnull()))]"
      ],
      "metadata": {
        "trusted": true,
        "id": "56SMMVAspJt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La variable `Comments`, très peu renseignée également, peux être supprimée :"
      ],
      "metadata": {
        "id": "4b-QrD70pJt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(\"Comments\", axis=1, inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "D2kR0ovZpJt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La variable identifiant les outliers peut être interessante pour nos analyses, cependant, dans la documentation, nous ne savons pas rééllement à quoi correspondent ces outliers. Nous allons donc supprimer les lignes mentionnant ces outliers."
      ],
      "metadata": {
        "id": "CyxQYjJ9pJt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[~data[\"Outlier\"].isnull()==False]\n",
        "data.drop('Outlier', axis=1, inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "BfKB64CEpJt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons pour le moment conserver les autres variables en l'état. Une courte analyse exploratoire nous en apprendra plus sur les données à conserver."
      ],
      "metadata": {
        "id": "jgBh4xEvpJt_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#337da4\" id=\"section_2\">2. Analyse exploratoire & Feature Engineering</font>\n",
        "\n",
        "Dans un premier temps, nous allons regarder la répartition des divers types de bâtiments à étudier :\n",
        "\n",
        "### <font color=\"#2cb7b0\" id=\"section_2_1\">2.1. Les types de bâtiments</font>"
      ],
      "metadata": {
        "id": "ReBxhanvpJt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "building_type = data.groupby(by='BuildingType')['OSEBuildingID'].nunique()\n",
        "\n",
        "font_title = {'family': 'serif',\n",
        "              'color':  '#1d479b',\n",
        "              'weight': 'bold',\n",
        "              'size': 18,\n",
        "             }\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8,8))\n",
        "ax.pie(building_type.values, labels=building_type.index,\n",
        "       autopct='%1.1f%%', shadow=True, startangle=30,\n",
        "       textprops=dict(color=\"black\",size=12, weight=\"bold\"))\n",
        "ax.axis('equal')\n",
        "ax.set_title(\"Répartition des types de bâtiments du Dataset\", fontdict=font_title)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "cCNp2c59pJt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "la majeur partie des bâtiments sont typés **\"NonResidential\"**. Nous pouvons visualiser les diverses catégories représentées dans ce type de bâtiments :"
      ],
      "metadata": {
        "id": "w73-Z8PspJt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[(data['BuildingType']==\"NonResidential\"),'PrimaryPropertyType'].value_counts()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Etj_PSNgpJt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici, on remarque que des catégories sont des **doublons avec un caractère d'échappement**. Nous allons corriger ce problème :"
      ],
      "metadata": {
        "id": "rBBKoMIgpJt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "regex = re.compile(r'[\\n\\r\\t]')\n",
        "data['PrimaryPropertyType'] = [regex.sub(\"\", item) for index, item in data.PrimaryPropertyType.iteritems()]\n",
        "data.loc[(data['BuildingType']==\"NonResidential\"),'PrimaryPropertyType'].value_counts()"
      ],
      "metadata": {
        "trusted": true,
        "id": "7nZfo4GypJuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les bureaux de petite et moyenne taille représentent la plus grande part des bâtiments non résidentiels.\n",
        "\n",
        "### <font color=\"#2cb7b0\" id=\"section_2_2\">2.2. Les années de construction</font>\n",
        "Nous allons regarder les distribution des années de construction des bâtiments de Seattle :"
      ],
      "metadata": {
        "id": "N5a7IjwEpJuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(12,8))\n",
        "ax = sns.histplot(data=data, x='YearBuilt', bins=int((data.YearBuilt.max() - data.YearBuilt.min())/5))\n",
        "ax.set_xlabel(\"Année de construction\")\n",
        "ax.set_ylabel(\"Nombre de bâtiments\")\n",
        "plt.title(f\"Distribution des années de construction des bâtiments\\n\", fontdict=font_title)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "wb3lJU_gpJuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plus que l'année de construction, il serait intéressant de traiter l'**age des bâtiments** pour réduire la dispersion des données et lier l'année des relevés. Nous allons donc créer cette nouvelle variable et supprimer l'année de construction :"
      ],
      "metadata": {
        "id": "_O8n2BjTpJuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['BuildingAge'] = data['DataYear'] - data['YearBuilt']\n",
        "data.drop('YearBuilt', axis=1, inplace=True)\n",
        "\n",
        "fig = plt.figure(figsize=(12,8))\n",
        "ax = sns.histplot(data=data, x='BuildingAge', bins=int((data.BuildingAge.max() - data.BuildingAge.min())/5))\n",
        "ax.set_xlabel(\"Age du bâtiment\")\n",
        "ax.set_ylabel(\"Nombre de bâtiments\")\n",
        "plt.title(f\"Distribution de l'âge des bâtiments\\n\", fontdict=font_title)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "4v0QdN2NpJuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=\"#2cb7b0\" id=\"section_2_3\">2.3. Les corrélations linéaires</font>"
      ],
      "metadata": {
        "id": "RN351A0wpJuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr = data.corr()\n",
        "mask = np.zeros_like(corr)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "fig, ax = plt.subplots(figsize=(15,15))\n",
        "ax = sns.heatmap(corr, annot=True, fmt=\".2f\", annot_kws={'size':8},\n",
        "                 mask=mask, center=0, cmap=\"coolwarm\")\n",
        "plt.title(f\"Heatmap des corrélations linéaires\\n\",\n",
        "          fontdict=font_title)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "5JW1-Q4tpJuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour les varaibles à prédire `TotalGHGEmissions` et `SiteEnergyUse(kBtu)`, on remarque des corrélations linéaires quasi similaires avec les variables de relevés (les consommations) mais également avec le nombre de batiments ou d'étages ains que les surfaces au sol.\n",
        "\n",
        "On remarque sur ce Heatmap de fortes corrélations linéaires entre variables. Ces corrélations peuvent amener des problèmes de colinéarité dans nos futurs modèles. Isolons donc les **paires de variables avec des corrélations de Pearson supérieurs à 0.7** :"
      ],
      "metadata": {
        "id": "Pd7lkZ17pJuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.7\n",
        "corr_pairs = corr.unstack().sort_values(kind=\"quicksort\")\n",
        "strong_corr = (pd.DataFrame(corr_pairs[(abs(corr_pairs) > threshold)])\n",
        "               .reset_index().rename(columns={0:'corr_coeff'}))\n",
        "strong_corr = strong_corr[(strong_corr.index%2 == 0) & (strong_corr['level_0'] != strong_corr['level_1'])]\n",
        "strong_corr.sort_values('corr_coeff', ascending=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "GTa4NltipJuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On remarque que les variables suffixées GFA présentent de fortes corrélations avec plusieurs autres variables. Nous allons donc **créer de nouvelles variables** pour tenter de gommer ces corrélations linéaires :"
      ],
      "metadata": {
        "id": "2maHFsLppJuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_words(df, column = None):\n",
        "  list_words = set()\n",
        "  for word in df[column].str.split(','):\n",
        "    if isinstance(word, float):\n",
        "      continue\n",
        "    list_words = set().union(word, list_words)\n",
        "  return list(list_words)\n",
        "\n",
        "list_use_type = split_words(data, 'ListOfAllPropertyUseTypes')\n",
        "print(\"Nombre de type d'usages dans la base : {}\".format(len(list_use_type)))"
      ],
      "metadata": {
        "trusted": true,
        "id": "rDojawNbpJuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Réaliser un OneHotEncoder sur 117 types d'usage ne serait pas oportun. Nous allons donc créer une variable nous donnant le **nombre total d'usage du bâtiment**, puis supprimer la liste complète des usages :"
      ],
      "metadata": {
        "id": "nNl5ySD_pJuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['TotalUseTypeNumber'] = [str(word).count(\",\") + 1 for word in data['ListOfAllPropertyUseTypes'].str.split(',')]\n",
        "data.drop('ListOfAllPropertyUseTypes', axis=1, inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "pC5RyITZpJuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons à présent convertir les différentes surfaces (Buildings et Parking) en **pourcentage de la surface totale** et nous conserverons uniquement ces 2 variables en supprimant les variables `LargestPropertyUseTypeGFA`, `SecondLargestPropertyUseTypeGFA`, `ThirdLargestPropertyUseTypeGFA` :"
      ],
      "metadata": {
        "id": "7gPx_YsppJuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gfa_features = search_componant(data, suffix='GFA')\n",
        "data[['TotalUseTypeNumber'] + gfa_features].head(10)"
      ],
      "metadata": {
        "trusted": true,
        "id": "kfxO4GMrpJuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#On calcule les ratios\n",
        "data['GFABuildingRate'] = (round((data['PropertyGFABuilding(s)'].fillna(0)\n",
        "                                  /data['PropertyGFATotal'].fillna(0)),5))\n",
        "data['GFAParkingRate'] = (round((data['PropertyGFAParking'].fillna(0)\n",
        "                                 /data['PropertyGFATotal'].fillna(0)),5))\n",
        "\n",
        "#On supprime les variables inutiles\n",
        "data.drop(['LargestPropertyUseTypeGFA',\n",
        "           'SecondLargestPropertyUseTypeGFA',\n",
        "           'SecondLargestPropertyUseType',\n",
        "           'ThirdLargestPropertyUseTypeGFA',\n",
        "           'ThirdLargestPropertyUseType',\n",
        "           'PropertyGFAParking',\n",
        "           'PropertyGFABuilding(s)'],\n",
        "         axis=1, inplace=True)\n",
        "\n",
        "#On complète les usages de la partie la plus large\n",
        "data['LargestPropertyUseType'] = data['LargestPropertyUseType'].fillna(\"Unknown\")\n",
        "data['NumberofFloors'] = data['NumberofFloors'].fillna(1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "fnRsWS4epJuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous pouvons également calculer la **surface moyenne par bâtiment et par étage** :"
      ],
      "metadata": {
        "id": "EBthI2LtpJuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['GFAPerBuilding'] = round((data['PropertyGFATotal'] / data['NumberofBuildings']),3)\n",
        "data['GFAPerFloor'] = round((data['PropertyGFATotal'] / data['NumberofFloors']),3)"
      ],
      "metadata": {
        "trusted": true,
        "id": "7-OLLNFapJuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "trusted": true,
        "id": "fo54ljdepJuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les données sont à présent bien complétées. Nous allons vérifier l'impact de ce feature engineering sur la matrice des corrélations linéaires :"
      ],
      "metadata": {
        "id": "B8TwNjKwpJuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr = data.corr()\n",
        "mask = np.zeros_like(corr)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "fig, ax = plt.subplots(figsize=(15,15))\n",
        "ax = sns.heatmap(corr, annot=True, fmt=\".2f\", annot_kws={'size':8},\n",
        "                 mask=mask, center=0, cmap=\"coolwarm\")\n",
        "plt.title(f\"Heatmap des corrélations linéaires\\n\",\n",
        "          fontdict=font_title)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "s6wGZhIrpJuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.7\n",
        "corr_pairs = corr.unstack().sort_values(kind=\"quicksort\")\n",
        "strong_corr = (pd.DataFrame(corr_pairs[(abs(corr_pairs) > threshold)])\n",
        "               .reset_index().rename(columns={0:'corr_coeff'}))\n",
        "strong_corr = strong_corr[(strong_corr.index%2 == 0) & (strong_corr['level_0'] != strong_corr['level_1'])]\n",
        "strong_corr.sort_values('corr_coeff', ascending=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "v8m0T3rCpJuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vérification de **multicolinéarité avec le VIF** *(Variance Inflation Factor)* : $VIF = \\frac{1}{1-R^2}$"
      ],
      "metadata": {
        "id": "Ggrb0Np3pJuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "strong_corr_features = list(set(list(strong_corr['level_0'].values) + list(strong_corr['level_1'].values)))\n",
        "X = data[strong_corr_features].replace([np.inf, -np.inf], np.nan)\n",
        "X = X.dropna()\n",
        "\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"feature\"] = X.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n",
        "                   for i in range(len(X.columns))]\n",
        "vif_data[vif_data['VIF'] > 5]"
      ],
      "metadata": {
        "trusted": true,
        "id": "UQ556ll8pJuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Des scores VIF supérieur à 5 indiquent généralement une forte multicolinéarité. Ces variables fortement corrélées risquent d'impacter nos modèles.       \n",
        "Les features suffixées `EUI(kBtu/sf)`, sont des variables dont les valeurs sont ramenées à la surface par étage. Nous allons les supprimer car nous avons créer des variables pouvant permettre de ramener nos données à l'étage ou au building. Idem pour la variable `GHGEmissionsIntensity`"
      ],
      "metadata": {
        "id": "qYXhty1lpJuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Eui_features = search_componant(data, suffix='EUI(kBtu/sf)') + ['GHGEmissionsIntensity']\n",
        "data.drop(Eui_features, axis=1, inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "gtUfaZcwpJuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=\"#2cb7b0\" id=\"section_2_4\">2.4. Analyse des variables à prédire</font>\n",
        "\n",
        "Pour rappel, les 2 variables à prédire dans le cadre de notre mission sont :\n",
        "- `TotalGHGEmissions`\n",
        "- `SiteEnergyUse(kBtu)`\n",
        "\n",
        "Nous allons donc réaliser quelques analyses exploratoires sur ces features :"
      ],
      "metadata": {
        "id": "xKs8aCXhpJuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=False, figsize=(20,8))\n",
        "left, width = 0, 1\n",
        "bottom, height = 0, 1\n",
        "right = left + width\n",
        "top = bottom + height\n",
        "\n",
        "sns.histplot(data=data, x=\"TotalGHGEmissions\", kde=True, ax=axes[0], color=\"#9C3E2D\", alpha=0.6)\n",
        "axes[0].set_title(\"Données d'emission de CO2 globales\", color='#2cb7b0')\n",
        "\n",
        "#Test de Kolmogorov-Smirnov\n",
        "kstest = stats.kstest(data['TotalGHGEmissions'].notnull(),'norm')\n",
        "axes[0].text(right, top, 'Test Kolmogorov-Smirnov \\n Pvalue: {:.2} \\n Stat: {:.2}'.format(kstest.pvalue, kstest.statistic),\n",
        "            horizontalalignment='right',\n",
        "            verticalalignment='top',\n",
        "            style='italic', transform=axes[0].transAxes, fontsize = 12,\n",
        "            bbox={'facecolor':'#00afe6', 'alpha':0.5, 'pad':0})\n",
        "\n",
        "sns.histplot(data=data[(data['TotalGHGEmissions']< 1000)], x=\"TotalGHGEmissions\", kde=True, ax=axes[1], color=\"#9C3E2D\", alpha=0.6)\n",
        "axes[1].set_title(\"Données d'emission de CO2 zoomées\", color='#2cb7b0')\n",
        "\n",
        "plt.suptitle(\"Distribution des emissions de CO2 relevées (2015-2016)\",\n",
        "             fontdict=font_title, fontsize=22)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "9AmxvtOWpJuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=False, figsize=(20,8))\n",
        "\n",
        "sns.histplot(data=data, x=\"SiteEnergyUse(kBtu)\", kde=True, ax=axes[0], color=\"#6D9C0E\", alpha=0.6)\n",
        "axes[0].set_title(\"Données de consommation d'énergie globales\", color='#2cb7b0')\n",
        "\n",
        "#Test de Kolmogorov-Smirnov\n",
        "kstest = stats.kstest(data['SiteEnergyUse(kBtu)'].notnull(),'norm')\n",
        "axes[0].text(right, top, 'Test Kolmogorov-Smirnov \\n Pvalue: {:.2} \\n Stat: {:.2}'.format(kstest.pvalue, kstest.statistic),\n",
        "            horizontalalignment='right',\n",
        "            verticalalignment='top',\n",
        "            style='italic', transform=axes[0].transAxes, fontsize = 12,\n",
        "            bbox={'facecolor':'#00afe6', 'alpha':0.5, 'pad':0})\n",
        "\n",
        "sns.histplot(data=data[(data['SiteEnergyUse(kBtu)']< 0.3*10**8)], x=\"SiteEnergyUse(kBtu)\", kde=True, ax=axes[1], color=\"#6D9C0E\", alpha=0.6)\n",
        "axes[1].set_title(\"Données de consommation d'énergie zoomées\", color='#2cb7b0')\n",
        "\n",
        "plt.suptitle(\"Distribution des consommation d'énergie relevées (2015-2016)\",\n",
        "             fontdict=font_title, fontsize=22)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "JlkVW8CzpJuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En se basant sur les projections obtenus et les résultats des tests de Kolmogorov-Smirnov *(Pvalue < au niveau de test de 5%)* on rejette donc l'hypothèse de normalité des distributions de ces variables.\n",
        "\n",
        "Projettons à présent les scatterplots des distribition de ces 2 variables entre elles :"
      ],
      "metadata": {
        "id": "Pa4U4upspJuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=False, figsize=(20,8))\n",
        "sns.scatterplot(data=data, x=\"TotalGHGEmissions\", y=\"SiteEnergyUse(kBtu)\", ax=axes[0])\n",
        "axes[0].set_title(\"Données globales\", color='#2cb7b0')\n",
        "sns.scatterplot(data=data[(data['TotalGHGEmissions'] < 5000)], x=\"TotalGHGEmissions\", y=\"SiteEnergyUse(kBtu)\", ax=axes[1])\n",
        "axes[1].set_title(\"Données zoomées\", color='#2cb7b0')\n",
        "plt.suptitle(\"Répartition des données de consommation d'énergie vs emissions de CO2\", fontdict=font_title, fontsize=22)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "qufbh1gVpJuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "on remarque ici que la répartion des données d'emission de CO2 en fonction de la consommation d'énergie ne suivent pas uniquement 1 seule droite de régression linéaire si l'on zoom sur les données les plus représentées.\n",
        "\n",
        "Regardons à présent si les **coordonnées géographiques** ont un impact sur les rejets et consommations. Pour cela, afin d'éviter les corrélations fortes entre Latitude et Longitude, nous allons calculer la **distance Harversine entre chaque point de coordonnées et le centre de Seattle** :"
      ],
      "metadata": {
        "id": "OjcfuYU6pJuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import radians, cos, sin, asin, sqrt\n",
        "\n",
        "#Coordonnées du centre de Seattle\n",
        "seattle_lat = 47.6062\n",
        "seattle_lon = -122.3321\n",
        "\n",
        "def haversine_distance(lat1, lng1, lat2, lng2, degrees=True):\n",
        "    r = 3956 # rayon de la Terre en miles\n",
        "\n",
        "    if degrees:\n",
        "        lat1, lng1, lat2, lng2 = map(radians, [lat1, lng1, lat2, lng2])\n",
        "\n",
        "    # Formule Haversine\n",
        "    dlng = lng2 - lng1\n",
        "    dlat = lat2 - lat1\n",
        "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlng/2)**2\n",
        "    d = 2 * r * asin(sqrt(a))\n",
        "\n",
        "    return d"
      ],
      "metadata": {
        "trusted": true,
        "id": "1HflE5VEpJuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calcul des distance au centre de Seattle pour chaque point\n",
        "data['harvesine_distance'] = [haversine_distance(seattle_lat, seattle_lon, x, y)\n",
        "                              for x, y in zip(data.Latitude.astype(float), data.Longitude.astype(float))]"
      ],
      "metadata": {
        "trusted": true,
        "id": "BbvLs4ADpJuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=False, figsize=(20,8))\n",
        "sns.scatterplot(data=data, y=\"TotalGHGEmissions\", x=\"harvesine_distance\", color=\"#9C3E2D\", ax=axes[0])\n",
        "axes[0].set_title(\"Données globales\", color='#2cb7b0')\n",
        "sns.histplot(data=data[(data['TotalGHGEmissions'] < 2500)], y=\"TotalGHGEmissions\",\n",
        "                x=\"harvesine_distance\", color=\"#9C3E2D\", ax=axes[1])\n",
        "axes[1].set_title(\"Données zoomées\", color='#2cb7b0')\n",
        "plt.suptitle(\"Répartition des données d'emissions de CO2 en fonction des coordonnées géographiques\",\n",
        "             fontdict=font_title, fontsize=22)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "xgJ-oH5kpJuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=False, figsize=(20,8))\n",
        "sns.scatterplot(data=data, y=\"SiteEnergyUse(kBtu)\", x=\"harvesine_distance\", color=\"#6D9C0E\", ax=axes[0])\n",
        "axes[0].set_title(\"Données globales\", color='#2cb7b0')\n",
        "sns.histplot(data=data[(data['SiteEnergyUse(kBtu)'] < 2*10**8)], y=\"SiteEnergyUse(kBtu)\",\n",
        "                x=\"harvesine_distance\", color=\"#6D9C0E\", ax=axes[1])\n",
        "axes[1].set_title(\"Données zoomées\", color='#2cb7b0')\n",
        "plt.suptitle(\"Répartition des données d'emissions de CO2 en fonction des coordonnées géographiques\",\n",
        "             fontdict=font_title, fontsize=22)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "HaJtj7G2pJuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En regardant ces projections, il semble que **les coordonnées géographiques *(donc les adresses des bâtiments)* puissent avoir un impact sur les consommations d'égergie et rejets de CO2**.\n",
        "\n",
        "D'autre part, la latitude et la longitude étant 2 variables fortement corrélées dans notre jeu de données, **nous allons supprimer ces 2 colonnes pour conserver uniquement ce point de coordonnée unique Harvesine** *(en fin de Notebook)*."
      ],
      "metadata": {
        "id": "Uec2oFhipJuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons à présent regarder la répartition de ces 2 variables en fonction du type de bâtiement."
      ],
      "metadata": {
        "id": "mGHgJbfYpJuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=False, figsize=(20,8))\n",
        "sns.barplot(x='BuildingType',y='TotalGHGEmissions',data=data, ax=axes[0])\n",
        "sns.barplot(x='BuildingType',y='SiteEnergyUse(kBtu)',data=data, ax=axes[1])\n",
        "plt.suptitle(\"Répartition de la consommation d'énergie et emissions de CO2 en fonction du type de bâtiment\",\n",
        "             fontdict=font_title, fontsize=18)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "0d6LAL8fpJuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sur ces diagrammes en barre, les campus se démarquent largement en terme de consommation et de rejets de CO2. Regardons à présent si l'âge des bâtiments a un impact sur les émissions de CO2 :"
      ],
      "metadata": {
        "id": "gGemkikNpJuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bins = pd.IntervalIndex.from_tuples([(0, 10), (10, 20), (20, 30), (30, 40), (40, 50),\n",
        "                                     (50, 60), (60, 70), (70,80), (80,90), (90,100),\n",
        "                                     (100,110), (110,120)])\n",
        "\n",
        "sns.catplot(\n",
        "    data=data, kind=\"bar\",\n",
        "    x=pd.cut(data['BuildingAge'], bins=bins), y=\"TotalGHGEmissions\",\n",
        "    ci=None, color=\"#9C3E2D\", alpha=.6,\n",
        "    height=7, aspect=2\n",
        ")\n",
        "plt.title(\"Influence de l'âge des bâtiments sur les émissions de CO2\", fontdict=font_title)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "P10fpmBTpJuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.catplot(\n",
        "    data=data, kind=\"bar\",\n",
        "    x=pd.cut(data['BuildingAge'], bins=bins), y=\"SiteEnergyUse(kBtu)\",\n",
        "    ci=None, color=\"#6D9C0E\", alpha=.6,\n",
        "    height=7, aspect=2\n",
        ")\n",
        "plt.title(\"Influence de l'âge des bâtiments sur les consommations d'énergie\", fontdict=font_title)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "maOsTs8rpJuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les bâtiments de moins de 30 ans semblent avoir des consommations d'énergie et rejets de CO2 plus important que les buildings anciens, alors même que la variable `BuildingAge` n'est pas fortement corrélée à d'autres features *(comme la taille des bâtiments par exemple)*."
      ],
      "metadata": {
        "id": "i9BAMQjzpJuH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#337da4\" id=\"section_3\">3. Dernières étapes de nettoyage</font>\n",
        "\n",
        "Nous allons éliminer certaines variables qui ne seront pas utiles pour nos modélisations et vérifier les données incomplètes identifiées dans le jeu de données initial."
      ],
      "metadata": {
        "id": "UIOGIVfVpJuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "trusted": true,
        "id": "RHfckIm8pJuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vérifions la variable `ComplianceStatus` qui représente la conformité des données relevées :"
      ],
      "metadata": {
        "id": "5YMI4kCdpJuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['ComplianceStatus'].unique()"
      ],
      "metadata": {
        "trusted": true,
        "id": "ERBwrIq_pJuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Nombre de ligne identifiées comme non conforme : {}.\".format(data[data['ComplianceStatus'] != \"Compliant\"].shape[0]))"
      ],
      "metadata": {
        "trusted": true,
        "id": "Rp8qeq_QpJuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[data['ComplianceStatus'] == \"Compliant\"]"
      ],
      "metadata": {
        "trusted": true,
        "id": "_mIO9ScipJuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons ensuite supprimer les variables `DefaultData`, `ComplianceStatus`, `TaxParcelIdentificationNumber`, `CouncilDistrictCode`, `City`"
      ],
      "metadata": {
        "id": "eHg9dZa3pJuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop(['DefaultData','ComplianceStatus', 'City',\n",
        "                  'TaxParcelIdentificationNumber','CouncilDistrictCode'], axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "hils7oDYpJuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#337da4\" id=\"section_4\">4. Projection des établissements sur la carte de Seattle</font>"
      ],
      "metadata": {
        "id": "mLxjK2X8pJuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import folium\n",
        "import folium.plugins\n",
        "\n",
        "seattle_map = folium.Map(location=[seattle_lat, seattle_lon], zoom_start=11)\n",
        "\n",
        "#Clusters\n",
        "marker_cluster = folium.plugins.MarkerCluster().add_to(seattle_map)\n",
        "for lat, lng, in zip(data.Latitude, data.Longitude):\n",
        "    folium.Marker(location=[lat, lng]).add_to(marker_cluster)\n",
        "\n",
        "seattle_map"
      ],
      "metadata": {
        "trusted": true,
        "id": "7RvidhQFpJuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Et pour finir, nous supprimons les variables `Latitude` et `Longitude` puis **nous exportons le fichier cleané pour les modélisations qui seront effectuées dans un second Notebook** (https://www.kaggle.com/michaelfumery/sea-building-energy-and-ghg-prediction)"
      ],
      "metadata": {
        "id": "V6cIykxGpJuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop(['Latitude','Longitude'], axis=1)\n",
        "data.set_index(\"OSEBuildingID\").to_csv(\"building-energy-cleaned.csv\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "VZu3qQcXpJuI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}